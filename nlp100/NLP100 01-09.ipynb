{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 文字列の逆順"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = 'stressed'\n",
    "# 解答案１\n",
    "''.join(list(reversed(str)))\n",
    "# 解答案２\n",
    "str[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'タクシー'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"パタトクカシーー\"\n",
    "# 解決案１\n",
    "str[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 「パトカー」＋「タクシー」＝「パタトクカシー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1 = \"パトカー\"\n",
    "str2 = \"タクシー\"\n",
    "# 解決案１\n",
    "''.join([str1[i // 2]  if i % 2 == 0 else str2[i // 2] for i in range(8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 1, 6, 9, 2, 7, 5, 3, 5, 8, 9, 7, 10]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "# 解決案１\n",
    "list(map(len, text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 'Hi', 'He': 'He', 'Li': 'Lied', 'Be': 'Because', 'B': 'Boron', 'C': 'Could', 'N': 'Not', 'O': 'Oxidize', 'F': 'Fluorine.', 'Ne': 'New', 'Na': 'Nations', 'Mi': 'Might', 'Al': 'Also', 'Si': 'Sign', 'P': 'Peace', 'S': 'Security', 'Cl': 'Clause.', 'Ar': 'Arthur', 'K': 'King', 'Ca': 'Can.'}\n"
     ]
    }
   ],
   "source": [
    "text = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n",
    "# 解決案\n",
    "dict = {word[0] if i in [0,4,5,6,7,8,14,15,18] else word[0:2]:word for i,word in enumerate(text.split())}\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I am', 'am an', 'an NLPer'],\n",
       " ['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ngram(text:str) -> list:\n",
    "    text_list = text.split()\n",
    "    char = ''.join(text.split())\n",
    "    ngram_word = [' '.join([text_list[i],text_list[i+1]]) for i in range(len(text_list) - 1)]\n",
    "    ngram_char = [''.join([char[i],char[i+1]]) for i in range(len(char) - 1)]\n",
    "    return [ngram_word,ngram_char]\n",
    "\n",
    "\n",
    "ngram(\"I am an NLPer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xの集合： {'ra', 'ar', 'di', 'is', 'se', 'pa', 'ad', 'ap'}\n",
      "Yの集合： {'ag', 'ra', 'ph', 'ar', 'gr', 'pa', 'ap'}\n",
      "XとYの和集合： {'ag', 'ra', 'ph', 'ar', 'di', 'is', 'gr', 'se', 'pa', 'ad', 'ap'}\n",
      "XとYの積集合： {'pa', 'ar', 'ra', 'ap'}\n",
      "XとYの差集合1： {'di', 'is', 'se', 'ad'}\n",
      "YとXの差集合2： {'gr', 'ag', 'ph'}\n",
      "seというbi-gramがXに含まれるか。：True\n",
      "seというbi-gramがYに含まれるか。：False\n"
     ]
    }
   ],
   "source": [
    "x = \"paraparaparadise\"\n",
    "y = \"paragraph\"\n",
    "X = [''.join([x[i],x[i+1]]) for i in range(len(x)-1)]\n",
    "Y = [''.join([y[i],y[i+1]]) for i in range(len(y)-1)]\n",
    "X_set = set(X)\n",
    "Y_set = set(Y)\n",
    "\n",
    "print(\"Xの集合： {}\".format(X_set))\n",
    "print(\"Yの集合： {}\".format(Y_set))\n",
    "\n",
    "# 和集合\n",
    "XY_union = X_set | Y_set\n",
    "print(\"XとYの和集合： {}\".format(XY_union))\n",
    "\n",
    "# 積集合\n",
    "XY_intersection = X_set & Y_set\n",
    "print(\"XとYの積集合： {}\".format(XY_intersection))\n",
    "\n",
    "# 差集合\n",
    "XY_difference1 = X_set - Y_set\n",
    "XY_difference2 = Y_set - X_set\n",
    "print(\"XとYの差集合1： {}\".format(XY_difference1))\n",
    "print(\"YとXの差集合2： {}\".format(XY_difference2))\n",
    "\n",
    "# se 判定\n",
    "X_check = X_set.issuperset({'se'})\n",
    "Y_check = Y_set.issuperset({'se'})\n",
    "print(\"seというbi-gramがXに含まれるか。：{}\".format(X_check))\n",
    "print(\"seというbi-gramがYに含まれるか。：{}\".format(Y_check))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "temp = lambda x,y,z: print(\"{0}時の{1}は{2}\".format(x,y,z))\n",
    "temp(12,\"気温\",22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "暗号化、複合化成功\n",
      "暗号化文字列：wpdl320whdp\n"
     ]
    }
   ],
   "source": [
    "def cipher(words:str) -> str:\n",
    "    return ''.join([chr(219 - ord(word)) if word.islower() else word for word in words])\n",
    "\n",
    "\n",
    "# lambda表記の場合\n",
    "cipher = lambda words: ''.join([chr(219 - ord(word)) if word.islower() else word for word in words])\n",
    "\n",
    "# 2つ目の引数 {1：元の文字列が英小文字の場合, 0：それ以外} (Option 暗号化の場合は無し)\n",
    "test = 'dkwo320dswk'\n",
    "cryption = cipher(test)\n",
    "decryption = cipher(cryption)\n",
    "if test == decryption:\n",
    "    print('暗号化、複合化成功')\n",
    "    print('暗号化文字列：{}'.format(cryption))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I colnd'ut bvileee that I colud auclatly uertsdnnad what I was rienadg : the pnnehamoel pewor of the haumn mind .\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def random_strin(metrix:str) -> str:\n",
    "    text_list = metrix.split()\n",
    "    for index, word in enumerate(text_list):\n",
    "        if len(word) <= 4:\n",
    "            continue\n",
    "        else:\n",
    "            a = [0]\n",
    "            a = a + random.sample(range(1,len(word)-1), k=len(word)-2) + [len(word)-1]\n",
    "            text_list[index] = ''.join(word[n] for n in a)\n",
    "    return ' '.join(text_list)\n",
    "\n",
    "\n",
    "random_strin(\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
